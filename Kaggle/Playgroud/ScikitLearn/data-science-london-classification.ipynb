{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['submission_no_normalization.csv', '.DS_Store', 'test.csv', 'working', 'submission_with_scaling.csv', 'trainLabels.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "import numpy as np0 \n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import cross_val_score\n",
    "import os\n",
    "print(os.listdir(\"/Users/szkfzx/datasets/ScikitLearn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/Users/szkfzx/datasets/ScikitLearn/train.csv',header = None)\n",
    "train_labels = pd.read_csv('/Users/szkfzx/datasets/ScikitLearn/trainLabels.csv',header = None)\n",
    "test_data =  pd.read_csv('/Users/szkfzx/datasets/ScikitLearn/test.csv',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "a389d95466aba7ddbcddceed9d9b4cbb54d4c734"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.299403</td>\n",
       "      <td>-1.226624</td>\n",
       "      <td>1.498425</td>\n",
       "      <td>-1.176150</td>\n",
       "      <td>5.289853</td>\n",
       "      <td>0.208297</td>\n",
       "      <td>2.404498</td>\n",
       "      <td>1.594506</td>\n",
       "      <td>-0.051608</td>\n",
       "      <td>0.663234</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.850465</td>\n",
       "      <td>-0.622990</td>\n",
       "      <td>-1.833057</td>\n",
       "      <td>0.293024</td>\n",
       "      <td>3.552681</td>\n",
       "      <td>0.717611</td>\n",
       "      <td>3.305972</td>\n",
       "      <td>-2.715559</td>\n",
       "      <td>-2.682409</td>\n",
       "      <td>0.101050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.174176</td>\n",
       "      <td>0.332157</td>\n",
       "      <td>0.949919</td>\n",
       "      <td>-1.285328</td>\n",
       "      <td>2.199061</td>\n",
       "      <td>-0.151268</td>\n",
       "      <td>-0.427039</td>\n",
       "      <td>2.619246</td>\n",
       "      <td>-0.765884</td>\n",
       "      <td>-0.093780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.819750</td>\n",
       "      <td>0.012037</td>\n",
       "      <td>2.038836</td>\n",
       "      <td>0.468579</td>\n",
       "      <td>-0.517657</td>\n",
       "      <td>0.422326</td>\n",
       "      <td>0.803699</td>\n",
       "      <td>1.213219</td>\n",
       "      <td>1.382932</td>\n",
       "      <td>-1.817761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.192222</td>\n",
       "      <td>-0.414371</td>\n",
       "      <td>0.067054</td>\n",
       "      <td>-2.233568</td>\n",
       "      <td>3.658881</td>\n",
       "      <td>0.089007</td>\n",
       "      <td>0.203439</td>\n",
       "      <td>-4.219054</td>\n",
       "      <td>-1.184919</td>\n",
       "      <td>-1.240310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.604501</td>\n",
       "      <td>0.750054</td>\n",
       "      <td>-3.360521</td>\n",
       "      <td>0.856988</td>\n",
       "      <td>-2.751451</td>\n",
       "      <td>-1.582735</td>\n",
       "      <td>1.672246</td>\n",
       "      <td>0.656438</td>\n",
       "      <td>-0.932473</td>\n",
       "      <td>2.987436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.573270</td>\n",
       "      <td>-0.580318</td>\n",
       "      <td>-0.866332</td>\n",
       "      <td>-0.603812</td>\n",
       "      <td>3.125716</td>\n",
       "      <td>0.870321</td>\n",
       "      <td>-0.161992</td>\n",
       "      <td>4.499666</td>\n",
       "      <td>1.038741</td>\n",
       "      <td>-1.092716</td>\n",
       "      <td>...</td>\n",
       "      <td>1.022959</td>\n",
       "      <td>1.275598</td>\n",
       "      <td>-3.480110</td>\n",
       "      <td>-1.065252</td>\n",
       "      <td>2.153133</td>\n",
       "      <td>1.563539</td>\n",
       "      <td>2.767117</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.619645</td>\n",
       "      <td>1.883397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.613071</td>\n",
       "      <td>-0.644204</td>\n",
       "      <td>1.112558</td>\n",
       "      <td>-0.032397</td>\n",
       "      <td>3.490142</td>\n",
       "      <td>-0.011935</td>\n",
       "      <td>1.443521</td>\n",
       "      <td>-4.290282</td>\n",
       "      <td>-1.761308</td>\n",
       "      <td>0.807652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513906</td>\n",
       "      <td>-1.803473</td>\n",
       "      <td>0.518579</td>\n",
       "      <td>-0.205029</td>\n",
       "      <td>-4.744566</td>\n",
       "      <td>-1.520015</td>\n",
       "      <td>1.830651</td>\n",
       "      <td>0.870772</td>\n",
       "      <td>-1.894609</td>\n",
       "      <td>0.408332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.299403 -1.226624  1.498425 -1.176150  5.289853  0.208297  2.404498   \n",
       "1 -1.174176  0.332157  0.949919 -1.285328  2.199061 -0.151268 -0.427039   \n",
       "2  1.192222 -0.414371  0.067054 -2.233568  3.658881  0.089007  0.203439   \n",
       "3  1.573270 -0.580318 -0.866332 -0.603812  3.125716  0.870321 -0.161992   \n",
       "4 -0.613071 -0.644204  1.112558 -0.032397  3.490142 -0.011935  1.443521   \n",
       "\n",
       "         7         8         9   ...        30        31        32        33  \\\n",
       "0  1.594506 -0.051608  0.663234  ... -0.850465 -0.622990 -1.833057  0.293024   \n",
       "1  2.619246 -0.765884 -0.093780  ... -0.819750  0.012037  2.038836  0.468579   \n",
       "2 -4.219054 -1.184919 -1.240310  ... -0.604501  0.750054 -3.360521  0.856988   \n",
       "3  4.499666  1.038741 -1.092716  ...  1.022959  1.275598 -3.480110 -1.065252   \n",
       "4 -4.290282 -1.761308  0.807652  ...  0.513906 -1.803473  0.518579 -0.205029   \n",
       "\n",
       "         34        35        36        37        38        39  \n",
       "0  3.552681  0.717611  3.305972 -2.715559 -2.682409  0.101050  \n",
       "1 -0.517657  0.422326  0.803699  1.213219  1.382932 -1.817761  \n",
       "2 -2.751451 -1.582735  1.672246  0.656438 -0.932473  2.987436  \n",
       "3  2.153133  1.563539  2.767117  0.215748  0.619645  1.883397  \n",
       "4 -4.744566 -1.520015  1.830651  0.870772 -1.894609  0.408332  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "f4e53aaeb4910e617c54769c8ed0f409c3366bee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 40), (9000, 40), (1000, 1))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape,test_data.shape,train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "6c0e4c4e386479e72fc7fdf922cc985bce2b5ffe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.025596</td>\n",
       "      <td>-0.024526</td>\n",
       "      <td>-0.024088</td>\n",
       "      <td>-0.002271</td>\n",
       "      <td>1.092329</td>\n",
       "      <td>-0.006250</td>\n",
       "      <td>0.497342</td>\n",
       "      <td>-0.037883</td>\n",
       "      <td>0.026391</td>\n",
       "      <td>-0.003597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030651</td>\n",
       "      <td>0.022951</td>\n",
       "      <td>-0.542491</td>\n",
       "      <td>-0.011608</td>\n",
       "      <td>-0.483507</td>\n",
       "      <td>0.033371</td>\n",
       "      <td>0.567185</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>-0.892659</td>\n",
       "      <td>0.609451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.008282</td>\n",
       "      <td>1.016298</td>\n",
       "      <td>0.979109</td>\n",
       "      <td>0.970575</td>\n",
       "      <td>4.538834</td>\n",
       "      <td>0.989128</td>\n",
       "      <td>2.118819</td>\n",
       "      <td>2.232256</td>\n",
       "      <td>1.001064</td>\n",
       "      <td>1.013520</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011645</td>\n",
       "      <td>1.001375</td>\n",
       "      <td>2.239939</td>\n",
       "      <td>1.022456</td>\n",
       "      <td>2.121281</td>\n",
       "      <td>1.007044</td>\n",
       "      <td>2.227876</td>\n",
       "      <td>0.997635</td>\n",
       "      <td>2.022022</td>\n",
       "      <td>2.045439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.365711</td>\n",
       "      <td>-3.492086</td>\n",
       "      <td>-2.695602</td>\n",
       "      <td>-3.460471</td>\n",
       "      <td>-16.421901</td>\n",
       "      <td>-3.041250</td>\n",
       "      <td>-7.224761</td>\n",
       "      <td>-6.509084</td>\n",
       "      <td>-3.145588</td>\n",
       "      <td>-2.749812</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.379194</td>\n",
       "      <td>-2.971125</td>\n",
       "      <td>-7.840890</td>\n",
       "      <td>-2.999564</td>\n",
       "      <td>-7.124105</td>\n",
       "      <td>-2.952358</td>\n",
       "      <td>-5.452254</td>\n",
       "      <td>-3.473913</td>\n",
       "      <td>-8.051722</td>\n",
       "      <td>-7.799086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.669010</td>\n",
       "      <td>-0.693937</td>\n",
       "      <td>-0.698830</td>\n",
       "      <td>-0.617557</td>\n",
       "      <td>-1.801997</td>\n",
       "      <td>-0.732265</td>\n",
       "      <td>-0.838619</td>\n",
       "      <td>-1.604037</td>\n",
       "      <td>-0.677562</td>\n",
       "      <td>-0.682220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.659457</td>\n",
       "      <td>-0.696032</td>\n",
       "      <td>-2.121943</td>\n",
       "      <td>-0.664550</td>\n",
       "      <td>-1.879247</td>\n",
       "      <td>-0.642861</td>\n",
       "      <td>-1.059786</td>\n",
       "      <td>-0.691162</td>\n",
       "      <td>-2.220126</td>\n",
       "      <td>-0.565041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.027895</td>\n",
       "      <td>-0.033194</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.862818</td>\n",
       "      <td>0.027041</td>\n",
       "      <td>0.582321</td>\n",
       "      <td>0.018809</td>\n",
       "      <td>0.022092</td>\n",
       "      <td>-0.036110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049416</td>\n",
       "      <td>0.049778</td>\n",
       "      <td>-0.568262</td>\n",
       "      <td>-0.028097</td>\n",
       "      <td>-0.493575</td>\n",
       "      <td>0.037732</td>\n",
       "      <td>0.455474</td>\n",
       "      <td>0.038284</td>\n",
       "      <td>-0.855470</td>\n",
       "      <td>0.779944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.762520</td>\n",
       "      <td>0.682753</td>\n",
       "      <td>0.661434</td>\n",
       "      <td>0.640743</td>\n",
       "      <td>3.843172</td>\n",
       "      <td>0.671456</td>\n",
       "      <td>1.913664</td>\n",
       "      <td>1.438304</td>\n",
       "      <td>0.741310</td>\n",
       "      <td>0.665364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747031</td>\n",
       "      <td>0.699917</td>\n",
       "      <td>0.939348</td>\n",
       "      <td>0.651374</td>\n",
       "      <td>1.005795</td>\n",
       "      <td>0.691800</td>\n",
       "      <td>2.122157</td>\n",
       "      <td>0.693535</td>\n",
       "      <td>0.388698</td>\n",
       "      <td>1.992193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.326246</td>\n",
       "      <td>3.583870</td>\n",
       "      <td>2.546507</td>\n",
       "      <td>3.088738</td>\n",
       "      <td>17.565345</td>\n",
       "      <td>3.102997</td>\n",
       "      <td>7.592666</td>\n",
       "      <td>7.130097</td>\n",
       "      <td>3.145258</td>\n",
       "      <td>3.919426</td>\n",
       "      <td>...</td>\n",
       "      <td>2.844792</td>\n",
       "      <td>3.688047</td>\n",
       "      <td>7.160379</td>\n",
       "      <td>3.353631</td>\n",
       "      <td>6.005818</td>\n",
       "      <td>3.420561</td>\n",
       "      <td>6.603499</td>\n",
       "      <td>3.492548</td>\n",
       "      <td>5.774120</td>\n",
       "      <td>6.803984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.025596    -0.024526    -0.024088    -0.002271     1.092329   \n",
       "std       1.008282     1.016298     0.979109     0.970575     4.538834   \n",
       "min      -3.365711    -3.492086    -2.695602    -3.460471   -16.421901   \n",
       "25%      -0.669010    -0.693937    -0.698830    -0.617557    -1.801997   \n",
       "50%       0.027895    -0.033194     0.008145     0.002327     0.862818   \n",
       "75%       0.762520     0.682753     0.661434     0.640743     3.843172   \n",
       "max       3.326246     3.583870     2.546507     3.088738    17.565345   \n",
       "\n",
       "                5            6            7            8            9   ...  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  ...   \n",
       "mean     -0.006250     0.497342    -0.037883     0.026391    -0.003597  ...   \n",
       "std       0.989128     2.118819     2.232256     1.001064     1.013520  ...   \n",
       "min      -3.041250    -7.224761    -6.509084    -3.145588    -2.749812  ...   \n",
       "25%      -0.732265    -0.838619    -1.604037    -0.677562    -0.682220  ...   \n",
       "50%       0.027041     0.582321     0.018809     0.022092    -0.036110  ...   \n",
       "75%       0.671456     1.913664     1.438304     0.741310     0.665364  ...   \n",
       "max       3.102997     7.592666     7.130097     3.145258     3.919426  ...   \n",
       "\n",
       "                30           31           32           33           34  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.030651     0.022951    -0.542491    -0.011608    -0.483507   \n",
       "std       1.011645     1.001375     2.239939     1.022456     2.121281   \n",
       "min      -3.379194    -2.971125    -7.840890    -2.999564    -7.124105   \n",
       "25%      -0.659457    -0.696032    -2.121943    -0.664550    -1.879247   \n",
       "50%       0.049416     0.049778    -0.568262    -0.028097    -0.493575   \n",
       "75%       0.747031     0.699917     0.939348     0.651374     1.005795   \n",
       "max       2.844792     3.688047     7.160379     3.353631     6.005818   \n",
       "\n",
       "                35           36           37           38           39  \n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
       "mean      0.033371     0.567185     0.006849    -0.892659     0.609451  \n",
       "std       1.007044     2.227876     0.997635     2.022022     2.045439  \n",
       "min      -2.952358    -5.452254    -3.473913    -8.051722    -7.799086  \n",
       "25%      -0.642861    -1.059786    -0.691162    -2.220126    -0.565041  \n",
       "50%       0.037732     0.455474     0.038284    -0.855470     0.779944  \n",
       "75%       0.691800     2.122157     0.693535     0.388698     1.992193  \n",
       "max       3.420561     6.603499     3.492548     5.774120     6.803984  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5b88b164debdc0b566bd01fa31f13eab25d3596e"
   },
   "source": [
    "## **PRE-PROCESSING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff70975dc29d8caa15117b3a5eb1cd1352989b6f"
   },
   "source": [
    "**Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "36a8220bb4888c9efde64d1fafe4494c10122abf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700, 40), (300, 40), (700, 1), (300, 1))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(train_data,train_labels, test_size = 0.30, random_state = 101)\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "820d03db37e29cb608fe5b927e35615fc0551dfe"
   },
   "source": [
    "## **CLASSIFICATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "13c377fc3feece33ae9a42d26713b093e03e1524"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes 0.8066666666666666\n",
      "KNN 0.9166666666666666\n",
      "Random Forest 0.86\n",
      "Logistic Regression 0.82\n",
      "SVM 0.9033333333333333\n",
      "Decision Tree 0.75\n",
      "XGBoost 0.87\n"
     ]
    }
   ],
   "source": [
    "# NAIBE BAYES\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(x_train,y_train.values.ravel()) \n",
    "# numpy中的ravel()、flatten()、squeeze()都有将多维数组转换为一维数组的功能，区别： \n",
    "# ravel()：如果没有必要，不会产生源数据的副本 \n",
    "# flatten()：返回源数据的副本 \n",
    "# squeeze()：只能对维数为1的维度降维 \n",
    "# reshape(-1)也可以“拉平”多维数组\n",
    "predicted= model.predict(x_test)\n",
    "print('Naive Bayes',accuracy_score(y_test, predicted))\n",
    "\n",
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(x_train,y_train.values.ravel())\n",
    "predicted= knn_model.predict(x_test)\n",
    "print('KNN',accuracy_score(y_test, predicted))\n",
    "\n",
    "#RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc_model = RandomForestClassifier(n_estimators = 100,random_state = 99)\n",
    "rfc_model.fit(x_train,y_train.values.ravel())\n",
    "predicted = rfc_model.predict(x_test)\n",
    "print('Random Forest',accuracy_score(y_test,predicted))\n",
    "\n",
    "#LOGISTIC REGRESSION\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(solver = 'saga')\n",
    "lr_model.fit(x_train,y_train.values.ravel())\n",
    "lr_predicted = lr_model.predict(x_test)\n",
    "print('Logistic Regression',accuracy_score(y_test, lr_predicted))\n",
    "\n",
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(gamma = 'auto')\n",
    "svc_model.fit(x_train,y_train.values.ravel())\n",
    "svc_predicted = svc_model.predict(x_test)\n",
    "print('SVM',accuracy_score(y_test, svc_predicted))\n",
    "\n",
    "#DECISON TREE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree_model = DecisionTreeClassifier()\n",
    "dtree_model.fit(x_train,y_train.values.ravel())\n",
    "dtree_predicted = dtree_model.predict(x_test)\n",
    "print('Decision Tree',accuracy_score(y_test, dtree_predicted))\n",
    "\n",
    "#XGBOOST\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_train,y_train.values.ravel())\n",
    "xgb_predicted = xgb.predict(x_test)\n",
    "print('XGBoost',accuracy_score(y_test, xgb_predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b77f9e1ae3d5a304bad72d37041b4d7683a048db"
   },
   "source": [
    "## **Feature Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "58b427189cd0907c095a071546f36c988ba87271",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "\n",
    "norm = Normalizer()\n",
    "x_norm_train = norm.fit_transform(x_train)\n",
    "x_norm_test = norm.transform(x_test)\n",
    "norm_train_data = norm.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "4bd5561a1b7ac28ffd3fc8f0b4266d1c64ab477e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy_score 0.8\n",
      "Naive Bayes cross_val_score 0.808\n",
      "KNN accuracy_score 0.8633333333333333\n",
      "KNN cross_val_score 0.9019999999999999\n",
      "Random Forest accuracy_score 0.8633333333333333\n",
      "Random Forest cross_val_score 0.8699999999999999\n",
      "Logistic Regression accuracy_score 0.8066666666666666\n",
      "Logistic Regression cross_val_score 0.8220000000000001\n",
      "SVM accuracy_score 0.7866666666666666\n",
      "SVM cross_val_score 0.808\n",
      "Decision Tree accuracy_score 0.8066666666666666\n",
      "Decision Tree cross_val_score 0.7929999999999999\n",
      "XGBoost cross_val_score 0.86\n",
      "XGBoost cross_val_score 0.8710000000000001\n"
     ]
    }
   ],
   "source": [
    "# NAIBE BAYES\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(x_norm_train,y_train.values.ravel())\n",
    "nb_predicted= nb_model.predict(x_norm_test)\n",
    "print('Naive Bayes accuracy_score',accuracy_score(y_test, nb_predicted))\n",
    "print('Naive Bayes cross_val_score',cross_val_score(nb_model,norm_train_data, train_labels.values.ravel(), cv=10).mean())\n",
    "\n",
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn_model.fit(x_norm_train,y_train.values.ravel())\n",
    "knn_predicted= knn_model.predict(x_norm_test)\n",
    "print('KNN accuracy_score',accuracy_score(y_test, knn_predicted))\n",
    "print('KNN cross_val_score',cross_val_score(knn_model,norm_train_data, train_labels.values.ravel(), cv=10).mean())\n",
    "\n",
    "#RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc_model = RandomForestClassifier(n_estimators = 100,random_state = 99)\n",
    "rfc_model.fit(x_norm_train,y_train.values.ravel())\n",
    "rfc_predicted = rfc_model.predict(x_norm_test)\n",
    "print('Random Forest accuracy_score',accuracy_score(y_test,rfc_predicted))\n",
    "print('Random Forest cross_val_score',cross_val_score(rfc_model,norm_train_data, train_labels.values.ravel(), cv=10).mean())\n",
    "\n",
    "#LOGISTIC REGRESSION\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(solver = 'saga')\n",
    "lr_model.fit(x_norm_train,y_train.values.ravel())\n",
    "lr_predicted = lr_model.predict(x_norm_test)\n",
    "print('Logistic Regression accuracy_score',accuracy_score(y_test, lr_predicted))\n",
    "print('Logistic Regression cross_val_score',cross_val_score(lr_model,norm_train_data, train_labels.values.ravel(), cv=10).mean())\n",
    "\n",
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(gamma = 'auto')\n",
    "svc_model.fit(x_norm_train,y_train.values.ravel())\n",
    "svc_predicted = svc_model.predict(x_norm_test)\n",
    "print('SVM accuracy_score',accuracy_score(y_test, svc_predicted))\n",
    "print('SVM cross_val_score',cross_val_score(svc_model,norm_train_data, train_labels.values.ravel(), cv=10).mean())\n",
    "\n",
    "#DECISON TREE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree_model = DecisionTreeClassifier()\n",
    "dtree_model.fit(x_norm_train,y_train.values.ravel())\n",
    "dtree_predicted = dtree_model.predict(x_norm_test)\n",
    "print('Decision Tree accuracy_score',accuracy_score(y_test, dtree_predicted))\n",
    "print('Decision Tree cross_val_score',cross_val_score(dtree_model,norm_train_data, train_labels.values.ravel(), cv=10).mean())\n",
    "\n",
    "#XGBOOST\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_norm_train,y_train.values.ravel())\n",
    "xgb_predicted = xgb.predict(x_norm_test)\n",
    "print('XGBoost cross_val_score',accuracy_score(y_test, xgb_predicted))\n",
    "print('XGBoost cross_val_score',cross_val_score(xgb,norm_train_data, train_labels.values.ravel(), cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "69d658df0437d39e54d281340770561e902c45bb"
   },
   "source": [
    "**KNN** gave maximum accuracy using Feature Scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ebfa1649b844d8aedf4cafc8d2e221ed239ab484"
   },
   "source": [
    "## **Principal Component Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_uuid": "ccde9fde1bfc32fbff1e4ff61cd4dd53d9d55ff9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35.46225556 29.08735744 11.36075127  7.12468937  6.9297776   6.35505477\n",
      "  5.90336048  4.42730441  3.26930364  2.97252656]\n",
      "[0.25054403 0.2055048  0.08026473 0.05033657 0.0489595  0.04489904\n",
      " 0.04170777 0.03127931 0.02309793 0.02100117]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca  = PCA(n_components=10)\n",
    "x_train = pca.fit_transform(x_train)\n",
    "x_test = pca.transform(x_test)\n",
    "pca_train_data = pca.fit_transform(train_data)\n",
    "explained_variance_ = pca.explained_variance_\n",
    "explained_variance_ratio_ = pca.explained_variance_ratio_\n",
    "# 第一个是explained_variance_，它代表降维后的各主成分的方差值。方差值越大，则说明越是重要的主成分。\n",
    "# 第二个是explained_variance_ratio_，它代表降维后的各主成分的方差值占总方差值的比例，这个比例越大，则越是重要的主成分。\n",
    "print(explained_variance_)\n",
    "print(explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_uuid": "0790f086bf5d80d9e2fd14e67718af596f8adb66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values.ravel().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "_uuid": "ecde51eda4ac6aa015e2ef0d528673d12175a2d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes 0.8459999999999999\n",
      "KNN 0.9099999999999999\n",
      "Random Forest 0.897\n",
      "Logistic Regression 0.8100000000000002\n",
      "SVM 0.905\n",
      "Decision Tree 0.79\n",
      "XGBoost 0.8700000000000001\n"
     ]
    }
   ],
   "source": [
    "# NAIBE BAYES\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "#nb_model.fit(pca_train_data,y_train.values.ravel())\n",
    "#nb_predicted= nb_model.predict(x_norm_test)\n",
    "#print('Naive Bayes',accuracy_score(y_test, nb_predicted))\n",
    "print('Naive Bayes',cross_val_score(nb_model,pca_train_data, train_labels.values.ravel(), cv=10).mean())\n",
    "\n",
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors = 5)\n",
    "#knn_model.fit(pca_train_data,y_train.values.ravel())\n",
    "#knn_predicted= knn_model.predict(x_norm_test)\n",
    "#print('KNN',accuracy_score(y_test, knn_predicted))\n",
    "print('KNN',cross_val_score(knn_model,pca_train_data, train_labels.values.ravel(), cv=10).mean())\n",
    "\n",
    "#RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc_model = RandomForestClassifier(n_estimators = 100,random_state = 99)\n",
    "#rfc_model.fit(pca_train_data,y_train.values.ravel())\n",
    "#rfc_predicted = rfc_model.predict(x_norm_test)\n",
    "#print('Random Forest',accuracy_score(y_test,rfc_predicted))\n",
    "print('Random Forest',cross_val_score(rfc_model,pca_train_data, train_labels.values.ravel(), cv=10).mean())\n",
    "\n",
    "#LOGISTIC REGRESSION\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(solver = 'saga')\n",
    "#lr_model.fit(pca_train_data,y_train.values.ravel())\n",
    "#lr_predicted = lr_model.predict(x_norm_test)\n",
    "#print('Logistic Regression',accuracy_score(y_test, lr_predicted))\n",
    "print('Logistic Regression',cross_val_score(lr_model,pca_train_data, train_labels.values.ravel(), cv=10).mean())\n",
    "\n",
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(gamma = 'auto')\n",
    "#svc_model.fit(x_norm_train,y_train.values.ravel())\n",
    "#svc_predicted = svc_model.predict(x_norm_test)\n",
    "#print('SVM',accuracy_score(y_test, svc_predicted))\n",
    "print('SVM',cross_val_score(svc_model,pca_train_data, train_labels.values.ravel(), cv=10).mean())\n",
    "\n",
    "#DECISON TREE\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree_model = DecisionTreeClassifier()\n",
    "#dtree_model.fit(x_norm_train,y_train.values.ravel())\n",
    "#dtree_predicted = dtree_model.predict(x_norm_test)\n",
    "#print('Decision Tree',accuracy_score(y_test, dtree_predicted))\n",
    "print('Decision Tree',cross_val_score(dtree_model,pca_train_data, train_labels.values.ravel(), cv=10).mean())\n",
    "\n",
    "#XGBOOST\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "#xgb.fit(x_norm_train,y_train.values.ravel())\n",
    "#xgb_predicted = xgb.predict(x_norm_test)\n",
    "#print('XGBoost',accuracy_score(y_test, xgb_predicted))\n",
    "print('XGBoost',cross_val_score(xgb,pca_train_data, train_labels.values.ravel(), cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7d75eaca957fbfd660f689d5423ab52126169f09"
   },
   "source": [
    "**KNN**, **Random** **Forest** and **SVM** gave maximum accuracy using Principal Component Analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e566216ec8270c627be9684f8124ca00446fab8e"
   },
   "source": [
    "## **Applying Gaussian Mixture and Grid Search to improve the accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1a001dd5de6d731ffad8507e9d3562574d8c8856"
   },
   "source": [
    "We select the above three algorithms (KNN, Random Forest and SVM) which  gave maximum accuracy for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "_uuid": "f5b587dc2d5f357e4a7153f27e665d9e022a5c7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_all shape : (10000, 40)\n",
      "Random Forest Best Score 0.996\n",
      "Random Forest Best Parmas {'max_depth': 3, 'n_estimators': 10}\n",
      "Random Forest Accuracy 0.9960000000000001\n",
      "KNN Best Score 0.996\n",
      "KNN Best Params {'n_neighbors': 3}\n",
      "KNN Accuracy 0.9960000000000001\n",
      "SVM Best Score 0.996\n",
      "SVM Best Params {'C': 1, 'kernel': 'linear'}\n",
      "SVM Accuracy 0.9960000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "x_all = np.r_[train_data,test_data]\n",
    "print('x_all shape :',x_all.shape)\n",
    "\n",
    "# USING THE GAUSSIAN MIXTURE MODEL \n",
    "lowest_bic = np.infty\n",
    "bic = []\n",
    "n_components_range = range(1, 7)\n",
    "cv_types = ['spherical', 'tied', 'diag', 'full']\n",
    "for cv_type in cv_types:\n",
    "    for n_components in n_components_range:\n",
    "        gmm = GaussianMixture(n_components=n_components,covariance_type=cv_type)\n",
    "        gmm.fit(x_all)\n",
    "        bic.append(gmm.aic(x_all))\n",
    "        if bic[-1] < lowest_bic:\n",
    "            lowest_bic = bic[-1]\n",
    "            best_gmm = gmm\n",
    "            \n",
    "best_gmm.fit(x_all)\n",
    "gmm_train = best_gmm.predict_proba(train_data)\n",
    "gmm_test = best_gmm.predict_proba(test_data)\n",
    "\n",
    "#Random Forest Classifier\n",
    "rfc = RandomForestClassifier(random_state=99)\n",
    "\n",
    "#USING GRID SEARCH\n",
    "n_estimators = [10, 50, 100, 200,400]\n",
    "max_depth = [3, 10, 20, 40]\n",
    "param_grid = dict(n_estimators=n_estimators,max_depth=max_depth)\n",
    "\n",
    "grid_search_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv = 10,scoring='accuracy',n_jobs=-1).fit(gmm_train, train_labels.values.ravel())\n",
    "rfc_best = grid_search_rfc.best_estimator_\n",
    "print('Random Forest Best Score',grid_search_rfc.best_score_)\n",
    "print('Random Forest Best Parmas',grid_search_rfc.best_params_)\n",
    "print('Random Forest Accuracy',cross_val_score(rfc_best,gmm_train, train_labels.values.ravel(), cv=10).mean())\n",
    "\n",
    "#KNN \n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#USING GRID SEARCH\n",
    "n_neighbors=[3,5,6,7,8,9,10]\n",
    "param_grid = dict(n_neighbors=n_neighbors)\n",
    "\n",
    "grid_search_knn = GridSearchCV(estimator=knn, param_grid=param_grid, cv = 10, n_jobs=-1,scoring='accuracy').fit(gmm_train,train_labels.values.ravel())\n",
    "knn_best = grid_search_knn.best_estimator_\n",
    "print('KNN Best Score', grid_search_knn.best_score_)\n",
    "print('KNN Best Params',grid_search_knn.best_params_)\n",
    "print('KNN Accuracy',cross_val_score(knn_best,gmm_train, train_labels.values.ravel(), cv=10).mean())\n",
    "\n",
    "#SVM\n",
    "svc = SVC()\n",
    "\n",
    "#USING GRID SEARCH\n",
    "parameters = [{'kernel':['linear'],'C':[1,10,100]},\n",
    "              {'kernel':['rbf'],'C':[1,10,100],'gamma':[0.05,0.0001,0.01,0.001]}]\n",
    "grid_search_svm = GridSearchCV(estimator=svc, param_grid=parameters, cv = 10, n_jobs=-1,scoring='accuracy').fit(gmm_train, train_labels.values.ravel())\n",
    "svm_best = grid_search_svm.best_estimator_\n",
    "print('SVM Best Score',grid_search_svm.best_score_)\n",
    "print('SVM Best Params',grid_search_svm.best_params_)\n",
    "print('SVM Accuracy',cross_val_score(svm_best,gmm_train, train_labels.values.ravel(), cv=10).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "a91fc25a04134bc18612db284f5f2d890973da83",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc_best.fit(gmm_train,train_labels.values.ravel())\n",
    "pred  = rfc_best.predict(gmm_test)\n",
    "rfc_best_pred = pd.DataFrame(pred)\n",
    "\n",
    "rfc_best_pred.index += 1\n",
    "\n",
    "rfc_best_pred.columns = ['Solution']\n",
    "rfc_best_pred['Id'] = np.arange(1,rfc_best_pred.shape[0]+1)\n",
    "rfc_best_pred = rfc_best_pred[['Id', 'Solution']]\n",
    "\n",
    "rfc_best_pred.to_csv('Submission_GMM_RFC.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8971</th>\n",
       "      <td>8971</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8972</th>\n",
       "      <td>8972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8973</th>\n",
       "      <td>8973</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8974</th>\n",
       "      <td>8974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8975</th>\n",
       "      <td>8975</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8976</th>\n",
       "      <td>8976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8977</th>\n",
       "      <td>8977</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8978</th>\n",
       "      <td>8978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8979</th>\n",
       "      <td>8979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8980</th>\n",
       "      <td>8980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8981</th>\n",
       "      <td>8981</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8982</th>\n",
       "      <td>8982</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8983</th>\n",
       "      <td>8983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8984</th>\n",
       "      <td>8984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8985</th>\n",
       "      <td>8985</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8986</th>\n",
       "      <td>8986</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8987</th>\n",
       "      <td>8987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>8988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8989</th>\n",
       "      <td>8989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8990</th>\n",
       "      <td>8990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8991</th>\n",
       "      <td>8991</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8992</th>\n",
       "      <td>8992</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8993</th>\n",
       "      <td>8993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8994</th>\n",
       "      <td>8994</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>8995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>8996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>8997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>8998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>8999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000</th>\n",
       "      <td>9000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  Solution\n",
       "1        1         1\n",
       "2        2         0\n",
       "3        3         1\n",
       "4        4         0\n",
       "5        5         0\n",
       "6        6         0\n",
       "7        7         0\n",
       "8        8         1\n",
       "9        9         0\n",
       "10      10         0\n",
       "11      11         1\n",
       "12      12         1\n",
       "13      13         0\n",
       "14      14         0\n",
       "15      15         0\n",
       "16      16         1\n",
       "17      17         0\n",
       "18      18         0\n",
       "19      19         1\n",
       "20      20         1\n",
       "21      21         0\n",
       "22      22         1\n",
       "23      23         1\n",
       "24      24         0\n",
       "25      25         1\n",
       "26      26         1\n",
       "27      27         0\n",
       "28      28         0\n",
       "29      29         1\n",
       "30      30         0\n",
       "...    ...       ...\n",
       "8971  8971         1\n",
       "8972  8972         0\n",
       "8973  8973         1\n",
       "8974  8974         0\n",
       "8975  8975         0\n",
       "8976  8976         1\n",
       "8977  8977         0\n",
       "8978  8978         1\n",
       "8979  8979         1\n",
       "8980  8980         1\n",
       "8981  8981         1\n",
       "8982  8982         1\n",
       "8983  8983         0\n",
       "8984  8984         0\n",
       "8985  8985         0\n",
       "8986  8986         1\n",
       "8987  8987         0\n",
       "8988  8988         1\n",
       "8989  8989         1\n",
       "8990  8990         1\n",
       "8991  8991         0\n",
       "8992  8992         1\n",
       "8993  8993         1\n",
       "8994  8994         1\n",
       "8995  8995         1\n",
       "8996  8996         1\n",
       "8997  8997         1\n",
       "8998  8998         1\n",
       "8999  8999         0\n",
       "9000  9000         1\n",
       "\n",
       "[9000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_best_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

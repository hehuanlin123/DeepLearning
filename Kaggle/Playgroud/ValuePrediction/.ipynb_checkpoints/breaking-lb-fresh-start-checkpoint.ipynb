{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "56f3c3499260fe04c9d0c6535f59ea3320b8c987",
    "collapsed": true
   },
   "source": [
    "Please go through Giba's post and kernel  to underrstand what this leak is all about\n",
    "https://www.kaggle.com/titericz/the-property-by-giba (kernel)\n",
    "https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/61329 (post)\n",
    "\n",
    "Also, go through this Jiazhen's kernel which finds more columns to exploit leak\n",
    "https://www.kaggle.com/johnfarrell/giba-s-property-extended-result\n",
    "\n",
    "I just exploit data property in brute force way and then fill in remaining by row non zero means! This should bring everyone on level-playing field.\n",
    "\n",
    "**Let the competition begin! :D**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/szkfzx/anaconda2/envs/python36/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from scipy.stats import mode, skew, kurtosis, entropy\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm.pandas(tqdm_notebook)\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv', 'train.csv', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"/Users/szkfzx/datasets/santander-value-prediction-challenge\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc37a766646b5993cef0bc87ad6882728dd20cb2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/Users/szkfzx/datasets/santander-value-prediction-challenge/train.csv\")\n",
    "test = pd.read_csv(\"/Users/szkfzx/datasets/santander-value-prediction-challenge/test.csv\")\n",
    "\n",
    "transact_cols = [f for f in train.columns if f not in [\"ID\", \"target\"]]\n",
    "y = np.log1p(train[\"target\"]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transact_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6dcfc4df1340c38bfeac43fd4d19ba2763b3b916"
   },
   "source": [
    "We take time series columns from [here](https://www.kaggle.com/johnfarrell/giba-s-property-extended-result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 选择时间序列的列\n",
    "cols = ['f190486d6', '58e2e02e6', 'eeb9cd3aa', '9fd594eec', '6eef030c1',\n",
    "       '15ace8c9f', 'fb0f5dbfe', '58e056e12', '20aa07010', '024c577b9',\n",
    "       'd6bb78916', 'b43a7cfd5', '58232a6fb', '1702b5bf0', '324921c7b', \n",
    "       '62e59a501', '2ec5b290f', '241f0f867', 'fb49e4212',  '66ace2992',\n",
    "       'f74e8f13d', '5c6487af1', '963a49cdc', '26fc93eb7', '1931ccfdd', \n",
    "       '703885424', '70feb1494', '491b9ee45', '23310aa6f', 'e176a204a',\n",
    "       '6619d81fc', '1db387535', 'fc99f9426', '91f701ba2',  '0572565c2',\n",
    "       '190db8488',  'adb64ff71', 'c47340d97', 'c5a231d81', '0ff32eb98'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d61c75092518f50a879e9e3d5883ab752f73912b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "CPU_CORES = 1\n",
    "def _get_leak(df, cols, lag=0):\n",
    "    \"\"\" To get leak value, we do following:\n",
    "       1. Get string of all values after removing first two time steps\n",
    "       2. For all rows we shift the row by two steps and again make a string\n",
    "       3. Just find rows where string from 2 matches string from 1\n",
    "       4. Get 1st time step of row in 3 (Currently, there is additional condition to only fetch value if we got exactly one match in step 3)\"\"\"\n",
    "    series_str = df[cols[lag+2:]].apply(lambda x: \"_\".join(x.round(2).astype(str)), axis=1)\n",
    "    series_shifted_str = df[cols].shift(lag+2, axis=1)[cols[lag+2:]].apply(lambda x: \"_\".join(x.round(2).astype(str)), axis=1)\n",
    "    target_rows = series_shifted_str.progress_apply(lambda x: np.where(x == series_str)[0])\n",
    "    target_vals = target_rows.apply(lambda x: df.loc[x[0], cols[lag]] if len(x)==1 else 0)\n",
    "    return target_vals\n",
    "\n",
    "def get_all_leak(df, cols=None, nlags=15):\n",
    "    \"\"\"\n",
    "    We just recursively fetch target value for different lags\n",
    "    \"\"\"\n",
    "    df =  df.copy()\n",
    "#     with Pool(processes=CPU_CORES) as p:\n",
    "#         res = [p.apply_async(_get_leak, args=(df, cols, i)) for i in range(nlags)]\n",
    "#         res = [r.get() for r in res]\n",
    "    for i in range(nlags):\n",
    "        print(\"Processing lag {}\".format(i))\n",
    "        df[\"leaked_target_\"+str(i)] = _get_leak(df, cols, i)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1158e5d98cda3d48d8ed8cc07d93b19829e5b412"
   },
   "outputs": [],
   "source": [
    "test[\"target\"] = train[\"target\"].mean()\n",
    "\n",
    "all_df = pd.concat([train[[\"ID\", \"target\"] + cols], test[[\"ID\", \"target\"]+ cols]]).reset_index(drop=True)\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c51d07c04c1af45bd4bc1f297f7416ce7dd88548",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NLAGS = 25 #Increasing this might help push score a bit\n",
    "all_df = get_all_leak(all_df, cols=cols, nlags=NLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1a9bc6b9a8a78fd0898668f899ae46245c2126e3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leaky_cols = [\"leaked_target_\"+str(i) for i in range(NLAGS)]\n",
    "train = train.join(all_df.set_index(\"ID\")[leaky_cols], on=\"ID\", how=\"left\")\n",
    "test = test.join(all_df.set_index(\"ID\")[leaky_cols], on=\"ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "24b1b9fbd1626397503ed142c6eeeef04970edf2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[[\"target\"]+leaky_cols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "23a5c3edd5556ee8e71d9d2659d9abcb9500ad5d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"nonzero_mean\"] = train[transact_cols].apply(lambda x: np.expm1(np.log1p(x[x!=0]).mean()), axis=1)\n",
    "test[\"nonzero_mean\"] = test[transact_cols].apply(lambda x: np.expm1(np.log1p(x[x!=0]).mean()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f9e85f6d8444bdd2ba144502a998558cb926efb8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We start with 1st lag target and recusrsively fill zero's\n",
    "train[\"compiled_leak\"] = 0\n",
    "test[\"compiled_leak\"] = 0\n",
    "for i in range(NLAGS):\n",
    "    train.loc[train[\"compiled_leak\"] == 0, \"compiled_leak\"] = train.loc[train[\"compiled_leak\"] == 0, \"leaked_target_\"+str(i)]\n",
    "    test.loc[test[\"compiled_leak\"] == 0, \"compiled_leak\"] = test.loc[test[\"compiled_leak\"] == 0, \"leaked_target_\"+str(i)]\n",
    "    \n",
    "print(\"Leak values found in train and test \", sum(train[\"compiled_leak\"] > 0), sum(test[\"compiled_leak\"] > 0))\n",
    "print(\"% of correct leaks values in train \", sum(train[\"compiled_leak\"] == train[\"target\"])/sum(train[\"compiled_leak\"] > 0))\n",
    "\n",
    "train.loc[train[\"compiled_leak\"] == 0, \"compiled_leak\"] = train.loc[train[\"compiled_leak\"] == 0, \"nonzero_mean\"]\n",
    "test.loc[test[\"compiled_leak\"] == 0, \"compiled_leak\"] = test.loc[test[\"compiled_leak\"] == 0, \"nonzero_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "49c9d5e53e52c4307aef6ac402868aaee8566700",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "np.sqrt(mean_squared_error(y, np.log1p(train[\"compiled_leak\"]).fillna(14.49)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc2e522df90f97456e67f26977fde364acf02876",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#submission\n",
    "sub = test[[\"ID\"]]\n",
    "sub[\"target\"] = test[\"compiled_leak\"]\n",
    "sub.to_csv(\"baseline_submission_with_leaks.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

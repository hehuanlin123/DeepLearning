{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "# 0、导入模块，生成模拟数据集\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "seed = 2\n",
    "\n",
    "def generateds():\n",
    "    # 基于seed产生随机数\n",
    "    rdm = np.random.RandomState(seed)\n",
    "    # 随机数返回300行2列的矩阵，表示300组坐标点（x0,x1）作为输入数据集\n",
    "    X = rdm.randn(300,2)\n",
    "    # 从X这个300行2列的矩阵中取出一行，判断如果两个坐标的平方和小于2，给Y赋值1，其余赋值0\n",
    "    # 作为输入数据集的标签（正确答案）\n",
    "    Y_ = [int(x0*x0 + x1*x1 < 2) for (x0,x1) in X]\n",
    "    # 遍历Y中的每一个元素，1赋值'red'，其余赋值'blue'，这样可视化显示时人可以直观区分\n",
    "    Y_c = [['red' if y else 'blue'] for y in Y_]\n",
    "    # 对数据集X和标签Y进行shape整理，第一个元素为-1表示，随第二个参数计算得到，第二个元素表示多少列，\n",
    "    # 把X整理为n行2列，把Y整理为n行1列\n",
    "    X = np.vstack(X).reshape(-1,2)\n",
    "    Y_ = np.vstack(Y_).reshape(-1,1)\n",
    "    return X,Y_,Y_c\n",
    "    \n",
    "# print X\n",
    "# print Y_\n",
    "# print Y_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1、定义神经网络的输入、参数和输出，定义前向传播过程\n",
    "def get_weight(shape,regularizer):\n",
    "    w = tf.Variable(tf.random_normal(shape),dtype=tf.float32)\n",
    "    tf.add_to_collection('losses',tf.contrib.layers.l2_regularizer(regularizer)(w))\n",
    "    return w\n",
    "\n",
    "def get_bias(shape):\n",
    "    b = tf.Variable(tf.constant(0.01,shape=shape))\n",
    "    return b\n",
    "\n",
    "def forward(x,regularizer):\n",
    "    w1 = get_weight([2,11],0.01)\n",
    "    b1 = get_bias([11])\n",
    "    y1 = tf.nn.relu(tf.matmul(x,w1)+b1)\n",
    "\n",
    "    w2 = get_weight([11,1],0.01)\n",
    "    b2 = get_bias([1])\n",
    "    y = tf.matmul(y1,w2)+b2 #输出层不过激活\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 steps,loss is: 17.866362\n",
      "After 2000 steps,loss is: 3.890806\n",
      "After 4000 steps,loss is: 0.707116\n",
      "After 6000 steps,loss is: 0.382985\n",
      "After 8000 steps,loss is: 0.302672\n",
      "After 10000 steps,loss is: 0.257676\n",
      "After 12000 steps,loss is: 0.226223\n",
      "After 14000 steps,loss is: 0.204883\n",
      "After 16000 steps,loss is: 0.188656\n",
      "After 18000 steps,loss is: 0.175907\n",
      "After 20000 steps,loss is: 0.165327\n",
      "After 22000 steps,loss is: 0.154748\n",
      "After 24000 steps,loss is: 0.147005\n",
      "After 26000 steps,loss is: 0.140371\n",
      "After 28000 steps,loss is: 0.134883\n",
      "After 30000 steps,loss is: 0.129942\n",
      "After 32000 steps,loss is: 0.125335\n",
      "After 34000 steps,loss is: 0.121195\n",
      "After 36000 steps,loss is: 0.117647\n",
      "After 38000 steps,loss is: 0.114597\n",
      "w1:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'w1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8102a27ac14b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-8102a27ac14b>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m#probs的shape调整成xx的样子\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"w1:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"b1:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"w2:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'w1' is not defined"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import generateds\n",
    "# import forward\n",
    "\n",
    "STEPS = 40000\n",
    "BATCH_SIZE = 30\n",
    "LEARNING_RATE_BASE = 0.001\n",
    "LEARNING_RATE_DECAY = 0.999\n",
    "LEARNING_RATE_STEP = 1\n",
    "REGULARIZER = 0.01\n",
    "\n",
    "def backward():\n",
    "    x = tf.placeholder(tf.float32,shape=(None,2))\n",
    "    y_ = tf.placeholder(tf.float32,shape=(None,1))\n",
    "    \n",
    "    X,Y_,Y_c = generateds()\n",
    "    \n",
    "    y = forward(x,REGULARIZER)\n",
    "    \n",
    "    global_step = tf.Variable(0,trainable=False)\n",
    "    \n",
    "    #定义指数下降学习率\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        LEARNING_RATE_BASE,\n",
    "        global_step,\n",
    "        LEARNING_RATE_STEP,\n",
    "        LEARNING_RATE_DECAY,\n",
    "        staircase=True)\n",
    "    \n",
    "    #定义损失函数\n",
    "    loss_mse = tf.reduce_mean(tf.square(y - y_))#不含正则化\n",
    "    loss_total = loss_mse + tf.add_n(tf.get_collection('losses'))#含正则化\n",
    "    \n",
    "    #定义反向传播方法：包含正则化\n",
    "    train_step = tf.train.AdamOptimizer(0.0001).minimize(loss_total)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        sess.run(init_op)\n",
    "        STEPS = 40000\n",
    "        for i in range(STEPS):\n",
    "            start = (i * BATCH_SIZE) % 300\n",
    "            end = start + BATCH_SIZE\n",
    "            sess.run(train_step,feed_dict={x:X[start:end],y_:Y_[start:end]})\n",
    "            if i % 2000 ==0:\n",
    "                loss_v = sess.run(loss_total,feed_dict={x:X,y_:Y_})\n",
    "                print \"After %d steps,loss is: %f\" % (i,loss_v)\n",
    "            \n",
    "        #xx在-3到3之间以步长为0.01，yy在-3到3之间以步长0.01，生成二维网格坐标点\n",
    "        xx,yy = np.mgrid[-3:3:.01,-3:3:.01]\n",
    "        #将xx yy拉直，并合并成一个2列的矩阵，得到一个网格坐标点的集合\n",
    "        grid = np.c_[xx.ravel(),yy.ravel()]\n",
    "        #将网格坐标点喂入神经网络，probs为输出\n",
    "        probs = sess.run(y,feed_dict={x:grid})\n",
    "        #probs的shape调整成xx的样子\n",
    "        probs = probs.reshape(xx.shape)\n",
    "    \n",
    "    plt.scatter(X[:,0],X[:,1],c=np.squeeze(Y_c))\n",
    "    plt.contour(xx,yy,probs,levels=[.5])\n",
    "    plt.show()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tfpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

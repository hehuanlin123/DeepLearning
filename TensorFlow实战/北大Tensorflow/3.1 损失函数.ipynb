{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[0.83494319 0.11482951]\n",
      " [0.66899751 0.46594987]\n",
      " [0.60181666 0.58838408]\n",
      " [0.31836656 0.20502072]\n",
      " [0.87043944 0.02679395]\n",
      " [0.41539811 0.43938369]\n",
      " [0.68635684 0.24833404]\n",
      " [0.97315228 0.68541849]\n",
      " [0.03081617 0.89479913]\n",
      " [0.24665715 0.28584862]\n",
      " [0.31375667 0.47718349]\n",
      " [0.56689254 0.77079148]\n",
      " [0.7321604  0.35828963]\n",
      " [0.15724842 0.94294584]\n",
      " [0.34933722 0.84634483]\n",
      " [0.50304053 0.81299619]\n",
      " [0.23869886 0.9895604 ]\n",
      " [0.4636501  0.32531094]\n",
      " [0.36510487 0.97365522]\n",
      " [0.73350238 0.83833013]\n",
      " [0.61810158 0.12580353]\n",
      " [0.59274817 0.18779828]\n",
      " [0.87150299 0.34679501]\n",
      " [0.25883219 0.50002932]\n",
      " [0.75690948 0.83429824]\n",
      " [0.29316649 0.05646578]\n",
      " [0.10409134 0.88235166]\n",
      " [0.06727785 0.57784761]\n",
      " [0.38492705 0.48384792]\n",
      " [0.69234428 0.19687348]\n",
      " [0.42783492 0.73416985]\n",
      " [0.09696069 0.04883936]]\n",
      "Y_:\n",
      "[[0.969797861054287], [1.1634604857835003], [1.1942714411690643], [0.5384488448601839], [0.8632760602061649], [0.8339321949148727], [0.9280893354024469], [1.6879345369421652], [0.9036674505700479], [0.512956535191759], [0.7844252375973886], [1.299175094270699], [1.0919817282657285], [1.0880495166868347], [1.1734589741814216], [1.3098158421478576], [1.2387201482616108], [0.8289679938936613], [1.3550486329517144], [1.578666175492443], [0.7524305484165053], [0.7326318868381032], [1.2449966435046544], [0.788097599402105], [1.5577488607336392], [0.3889256997930456], [1.0277860551407527], [0.6104042277890978], [0.8594808823356304], [0.8810757430061307], [1.1456401959033111], [0.1907476486033659]]\n",
      "w1:\n",
      "[[-0.8113182]\n",
      " [ 1.4845988]]\n",
      "\n",
      "\n",
      "After 0 training steps,w1 is: \n",
      "[[-0.80974597]\n",
      " [ 1.4852903 ]] \n",
      "\n",
      "After 500 training steps,w1 is: \n",
      "[[-0.46074435]\n",
      " [ 1.641878  ]] \n",
      "\n",
      "After 1000 training steps,w1 is: \n",
      "[[-0.21939856]\n",
      " [ 1.6984766 ]] \n",
      "\n",
      "After 1500 training steps,w1 is: \n",
      "[[-0.04415595]\n",
      " [ 1.7003176 ]] \n",
      "\n",
      "After 2000 training steps,w1 is: \n",
      "[[0.08942621]\n",
      " [1.673328  ]] \n",
      "\n",
      "After 2500 training steps,w1 is: \n",
      "[[0.19583555]\n",
      " [1.6322677 ]] \n",
      "\n",
      "After 3000 training steps,w1 is: \n",
      "[[0.28375748]\n",
      " [1.5854434 ]] \n",
      "\n",
      "After 3500 training steps,w1 is: \n",
      "[[0.35848638]\n",
      " [1.5374472 ]] \n",
      "\n",
      "After 4000 training steps,w1 is: \n",
      "[[0.42332518]\n",
      " [1.4907393 ]] \n",
      "\n",
      "After 4500 training steps,w1 is: \n",
      "[[0.48040026]\n",
      " [1.4465574 ]] \n",
      "\n",
      "After 5000 training steps,w1 is: \n",
      "[[0.53113604]\n",
      " [1.4054536 ]] \n",
      "\n",
      "After 5500 training steps,w1 is: \n",
      "[[0.5765325]\n",
      " [1.3675941]] \n",
      "\n",
      "After 6000 training steps,w1 is: \n",
      "[[0.61732584]\n",
      " [1.3329403 ]] \n",
      "\n",
      "After 6500 training steps,w1 is: \n",
      "[[0.6540846]\n",
      " [1.3013426]] \n",
      "\n",
      "After 7000 training steps,w1 is: \n",
      "[[0.6872685]\n",
      " [1.272602 ]] \n",
      "\n",
      "After 7500 training steps,w1 is: \n",
      "[[0.71725976]\n",
      " [1.2465005 ]] \n",
      "\n",
      "After 8000 training steps,w1 is: \n",
      "[[0.7443861]\n",
      " [1.2228197]] \n",
      "\n",
      "After 8500 training steps,w1 is: \n",
      "[[0.7689324]\n",
      " [1.2013483]] \n",
      "\n",
      "After 9000 training steps,w1 is: \n",
      "[[0.79115134]\n",
      " [1.1818889 ]] \n",
      "\n",
      "After 9500 training steps,w1 is: \n",
      "[[0.811267 ]\n",
      " [1.1642567]] \n",
      "\n",
      "After 10000 training steps,w1 is: \n",
      "[[0.8294814]\n",
      " [1.1482829]] \n",
      "\n",
      "After 10500 training steps,w1 is: \n",
      "[[0.84597576]\n",
      " [1.1338125 ]] \n",
      "\n",
      "After 11000 training steps,w1 is: \n",
      "[[0.8609128]\n",
      " [1.1207061]] \n",
      "\n",
      "After 11500 training steps,w1 is: \n",
      "[[0.87444043]\n",
      " [1.1088346 ]] \n",
      "\n",
      "After 12000 training steps,w1 is: \n",
      "[[0.88669145]\n",
      " [1.0980824 ]] \n",
      "\n",
      "After 12500 training steps,w1 is: \n",
      "[[0.8977863]\n",
      " [1.0883439]] \n",
      "\n",
      "After 13000 training steps,w1 is: \n",
      "[[0.9078348]\n",
      " [1.0795243]] \n",
      "\n",
      "After 13500 training steps,w1 is: \n",
      "[[0.91693527]\n",
      " [1.0715363 ]] \n",
      "\n",
      "After 14000 training steps,w1 is: \n",
      "[[0.92517716]\n",
      " [1.0643018 ]] \n",
      "\n",
      "After 14500 training steps,w1 is: \n",
      "[[0.93264157]\n",
      " [1.0577497 ]] \n",
      "\n",
      "After 15000 training steps,w1 is: \n",
      "[[0.9394023]\n",
      " [1.0518153]] \n",
      "\n",
      "After 15500 training steps,w1 is: \n",
      "[[0.9455251]\n",
      " [1.0464406]] \n",
      "\n",
      "After 16000 training steps,w1 is: \n",
      "[[0.95107025]\n",
      " [1.0415728 ]] \n",
      "\n",
      "After 16500 training steps,w1 is: \n",
      "[[0.9560928]\n",
      " [1.037164 ]] \n",
      "\n",
      "After 17000 training steps,w1 is: \n",
      "[[0.96064115]\n",
      " [1.0331714 ]] \n",
      "\n",
      "After 17500 training steps,w1 is: \n",
      "[[0.96476096]\n",
      " [1.0295546 ]] \n",
      "\n",
      "After 18000 training steps,w1 is: \n",
      "[[0.9684917]\n",
      " [1.0262802]] \n",
      "\n",
      "After 18500 training steps,w1 is: \n",
      "[[0.9718707]\n",
      " [1.0233142]] \n",
      "\n",
      "After 19000 training steps,w1 is: \n",
      "[[0.974931 ]\n",
      " [1.0206276]] \n",
      "\n",
      "After 19500 training steps,w1 is: \n",
      "[[0.9777026]\n",
      " [1.0181949]] \n",
      "\n",
      "\n",
      "\n",
      "Final w1 is:\n",
      "[[0.98019385]\n",
      " [1.0159807 ]]\n"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "#预测多或预测少的影响一样\n",
    "#0、导入模块，常量定义，生成模拟数据集\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "SEED = 23455\n",
    "\n",
    "#基于seed生成随机数\n",
    "rdm = np.random.RandomState(SEED)\n",
    "\n",
    "#随机数返回32行2列的矩阵，表示32组体积和重量，作为输入数据集\n",
    "X = rdm.rand(32,2)\n",
    "\n",
    "#作为输入数据集的标签（正确答案）\n",
    "Y_ = [[x1+x2+(rdm.rand()/10.0-0.05)] for (x1,x2) in X]\n",
    "\n",
    "#1、定义神经网络的输入、参数和输出，定义前向传播过程\n",
    "x = tf.placeholder(tf.float32,shape=(None,2))\n",
    "y_ = tf.placeholder(tf.float32,shape=(None,1))\n",
    "w1 = tf.Variable(tf.random_normal([2,1],stddev=1,seed=1))\n",
    "y = tf.matmul(x,w1)\n",
    "\n",
    "#2、定义损失函数及反向传播方法\n",
    "loss_mse = tf.reduce_mean(tf.square(y_-y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.001).minimize(loss_mse)\n",
    "#train_step = tf.train.MomentumOptimizer(0.001).minimize(loss)\n",
    "#train_step = tf.train.AdamDescentOptimizer(0.001).minimize(loss)\n",
    "\n",
    "#3、生成会话，训练STEPS轮\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    print \"X:\\n\",X\n",
    "    print \"Y_:\\n\",Y_\n",
    "    \n",
    "    #输出目前（未经训练）的参数取值\n",
    "    print \"w1:\\n\",sess.run(w1)\n",
    "    print \"\\n\"\n",
    "\n",
    "    #训练模型\n",
    "    STEPS = 20000\n",
    "    for i in range(STEPS):\n",
    "        start = (i*BATCH_SIZE) % 32\n",
    "        end = start + BATCH_SIZE\n",
    "        sess.run(train_step,feed_dict={x:X[start:end],y_:Y_[start:end]})\n",
    "        if i % 500 == 0:\n",
    "            print \"After %d training steps,w1 is: \" %(i)\n",
    "            print sess.run(w1),\"\\n\"\n",
    "\n",
    "    #输出训练后的参数取值\n",
    "    print \"\\n\"\n",
    "    print \"Final w1 is:\\n\",sess.run(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1:\n",
      "[[-0.8113182]\n",
      " [ 1.4845988]]\n",
      "\n",
      "\n",
      "After 0 training steps,w1 is: \n",
      "[[-0.762993 ]\n",
      " [ 1.5095658]] \n",
      "\n",
      "After 500 training steps,w1 is: \n",
      "[[1.0235443]\n",
      " [1.0463386]] \n",
      "\n",
      "After 1000 training steps,w1 is: \n",
      "[[1.0174844]\n",
      " [1.0406483]] \n",
      "\n",
      "After 1500 training steps,w1 is: \n",
      "[[1.0211805]\n",
      " [1.0472497]] \n",
      "\n",
      "After 2000 training steps,w1 is: \n",
      "[[1.0179386]\n",
      " [1.0412899]] \n",
      "\n",
      "After 2500 training steps,w1 is: \n",
      "[[1.0205938]\n",
      " [1.0390677]] \n",
      "\n",
      "After 3000 training steps,w1 is: \n",
      "[[1.0242898]\n",
      " [1.0456691]] \n",
      "\n",
      "After 3500 training steps,w1 is: \n",
      "[[1.01823  ]\n",
      " [1.0399789]] \n",
      "\n",
      "After 4000 training steps,w1 is: \n",
      "[[1.021926 ]\n",
      " [1.0465802]] \n",
      "\n",
      "After 4500 training steps,w1 is: \n",
      "[[1.0245812]\n",
      " [1.044358 ]] \n",
      "\n",
      "After 5000 training steps,w1 is: \n",
      "[[1.0185213]\n",
      " [1.0386678]] \n",
      "\n",
      "After 5500 training steps,w1 is: \n",
      "[[1.0245652]\n",
      " [1.0446368]] \n",
      "\n",
      "After 6000 training steps,w1 is: \n",
      "[[1.0185053]\n",
      " [1.0389466]] \n",
      "\n",
      "After 6500 training steps,w1 is: \n",
      "[[1.0222014]\n",
      " [1.045548 ]] \n",
      "\n",
      "After 7000 training steps,w1 is: \n",
      "[[1.0161415]\n",
      " [1.0398577]] \n",
      "\n",
      "After 7500 training steps,w1 is: \n",
      "[[1.0198376]\n",
      " [1.0464591]] \n",
      "\n",
      "After 8000 training steps,w1 is: \n",
      "[[1.0224928]\n",
      " [1.0442369]] \n",
      "\n",
      "After 8500 training steps,w1 is: \n",
      "[[1.0174738]\n",
      " [1.0473702]] \n",
      "\n",
      "After 9000 training steps,w1 is: \n",
      "[[1.0222716]\n",
      " [1.0383747]] \n",
      "\n",
      "After 9500 training steps,w1 is: \n",
      "[[1.0172527]\n",
      " [1.041508 ]] \n",
      "\n",
      "After 10000 training steps,w1 is: \n",
      "[[1.0199078]\n",
      " [1.0392858]] \n",
      "\n",
      "After 10500 training steps,w1 is: \n",
      "[[1.0236039]\n",
      " [1.0458871]] \n",
      "\n",
      "After 11000 training steps,w1 is: \n",
      "[[1.017544 ]\n",
      " [1.0401969]] \n",
      "\n",
      "After 11500 training steps,w1 is: \n",
      "[[1.0212401]\n",
      " [1.0467982]] \n",
      "\n",
      "After 12000 training steps,w1 is: \n",
      "[[1.0238953]\n",
      " [1.044576 ]] \n",
      "\n",
      "After 12500 training steps,w1 is: \n",
      "[[1.0178354]\n",
      " [1.0388858]] \n",
      "\n",
      "After 13000 training steps,w1 is: \n",
      "[[1.0215315]\n",
      " [1.0454872]] \n",
      "\n",
      "After 13500 training steps,w1 is: \n",
      "[[1.0154716]\n",
      " [1.039797 ]] \n",
      "\n",
      "After 14000 training steps,w1 is: \n",
      "[[1.0191677]\n",
      " [1.0463983]] \n",
      "\n",
      "After 14500 training steps,w1 is: \n",
      "[[1.0162914]\n",
      " [1.0427582]] \n",
      "\n",
      "After 15000 training steps,w1 is: \n",
      "[[1.0189465]\n",
      " [1.040536 ]] \n",
      "\n",
      "After 15500 training steps,w1 is: \n",
      "[[1.0216017]\n",
      " [1.0383139]] \n",
      "\n",
      "After 16000 training steps,w1 is: \n",
      "[[1.0252978]\n",
      " [1.0449152]] \n",
      "\n",
      "After 16500 training steps,w1 is: \n",
      "[[1.0192379]\n",
      " [1.039225 ]] \n",
      "\n",
      "After 17000 training steps,w1 is: \n",
      "[[1.022934 ]\n",
      " [1.0458263]] \n",
      "\n",
      "After 17500 training steps,w1 is: \n",
      "[[1.0168741]\n",
      " [1.0401361]] \n",
      "\n",
      "After 18000 training steps,w1 is: \n",
      "[[1.0205702]\n",
      " [1.0467374]] \n",
      "\n",
      "After 18500 training steps,w1 is: \n",
      "[[1.0232253]\n",
      " [1.0445153]] \n",
      "\n",
      "After 19000 training steps,w1 is: \n",
      "[[1.0171654]\n",
      " [1.038825 ]] \n",
      "\n",
      "After 19500 training steps,w1 is: \n",
      "[[1.0208615]\n",
      " [1.0454264]] \n",
      "\n",
      "\n",
      "\n",
      "Final w1 is:\n",
      "[[1.020171 ]\n",
      " [1.0425103]]\n"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "#预测多或预测少的影响一样\n",
    "#0、导入模块，常量定义，生成模拟数据集\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "SEED = 23455\n",
    "\n",
    "#酸奶成本1元，酸奶利润9元\n",
    "#预测少了损失大，故不要预测少，故生成的模型会多预测一些\n",
    "COST = 1\n",
    "PROFIT = 9\n",
    "\n",
    "#基于seed生成随机数\n",
    "rdm = np.random.RandomState(SEED)\n",
    "\n",
    "#随机数返回32行2列的矩阵，表示32组体积和重量，作为输入数据集\n",
    "X = rdm.rand(32,2)\n",
    "\n",
    "#作为输入数据集的标签（正确答案）\n",
    "Y_ = [[x1+x2+(rdm.rand()/10.0-0.05)] for (x1,x2) in X]\n",
    "\n",
    "#1、定义神经网络的输入、参数和输出，定义前向传播过程\n",
    "x = tf.placeholder(tf.float32,shape=(None,2))\n",
    "y_ = tf.placeholder(tf.float32,shape=(None,1))\n",
    "w1 = tf.Variable(tf.random_normal([2,1],stddev=1,seed=1))\n",
    "y = tf.matmul(x,w1)\n",
    "\n",
    "#2、定义损失函数及反向传播方法\n",
    "#自定义损失函数使得预测少了的损失大，于是模型应该偏向多的方向预测\n",
    "loss = tf.reduce_sum(tf.where(tf.greater(y,y_),(y-y_)*COST,(y_-y)*PROFIT))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n",
    "\n",
    "#3、生成会话，训练STEPS轮\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    #输出目前（未经训练）的参数取值\n",
    "    print \"w1:\\n\",sess.run(w1)\n",
    "    print \"\\n\"\n",
    "\n",
    "    #训练模型\n",
    "    STEPS = 20000\n",
    "    for i in range(STEPS):\n",
    "        start = (i*BATCH_SIZE) % 32\n",
    "        end = start + BATCH_SIZE\n",
    "        sess.run(train_step,feed_dict={x:X[start:end],y_:Y_[start:end]})\n",
    "        if i % 500 == 0:\n",
    "            print \"After %d training steps,w1 is: \" %(i)\n",
    "            print sess.run(w1),\"\\n\"\n",
    "\n",
    "    #输出训练后的参数取值\n",
    "    print \"\\n\"\n",
    "    print \"Final w1 is:\\n\",sess.run(w1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tfpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、思路\n",
    "\n",
    "### 1、特征选择是否有必要？\n",
    "\n",
    "在这个task没有必要。原因如下：\n",
    "\n",
    "（1）数据是脱敏过的，数据的每一维看不出数据的业务意义，做特征选择也就失去了方向，很有可能选择的或者去掉的特征是错误的。\n",
    "\n",
    "（2）根据每个特征的分布来筛选，同样是没那么必要，回归问题通常会在整个实数域的，不能说测试集上的数据分布有些许不同，就去掉这个特征，真实的数据应该就是这样的。将训练集和测试集的所有数据合并起来做一下Normalization，将特征分布对齐的到同一个分布即可。\n",
    "\n",
    "# 二、实现\n",
    "\n",
    "神经网络可以拟合任意函数，这里选用神经网络来解这个问题。（注：深度学习非常容易过拟合，训练的时候要特别小心）。\n",
    "\n",
    "（1）第一个网络结构如下，任意叠起几个全连接层，效果不理想。\n",
    "\n",
    "![image.png](http://jupter-oss.oss-cn-hangzhou.aliyuncs.com/public/files/image/1095279297005/1558585245842_hIPIF8VLWK.jpg)\n",
    "\n",
    "（2）第二个网络结构，发现特征分开输入会有比较好的效果，网络更容易学到隐含的关系，input拆开成6个，前5个7维，最后一个3维，并加入少量dropOut对抗过拟合，迭代次数不宜太多，600到800次即可。整个训练过程循环20次，也就是构建20个deep神经网络，更容易抵消误差。结构如下。训练好可以拿到0.117x的MSE\n",
    "    \n",
    "![image.png](http://jupter-oss.oss-cn-hangzhou.aliyuncs.com/public/files/image/1095279297005/1558585277898_LAkiCfbcq1.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
